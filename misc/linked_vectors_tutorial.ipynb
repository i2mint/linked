{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction from High-Dimensional Vector Data\n",
    "## Complete Tutorial for `linked.datasrc.vectors`\n",
    "\n",
    "This notebook provides a comprehensive guide to building graphs from vector data using the `linked.datasrc.vectors` module. We'll cover installation, basic usage, and advanced techniques with working examples.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction & Installation](#introduction)\n",
    "2. [Quick Start](#quick-start)\n",
    "3. [Graph Construction Methods](#methods)\n",
    "   - k-Nearest Neighbors Graph\n",
    "   - Mutual k-NN Graph\n",
    "   - Epsilon-Neighborhood Graph\n",
    "   - Adaptive k-NN Graph\n",
    "   - Random Graphs\n",
    "4. [Working Examples](#examples)\n",
    "5. [Performance & Scaling](#performance)\n",
    "6. [Best Practices](#best-practices)\n",
    "7. [Integration Examples](#integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction & Installation <a id=\"introduction\"></a>\n",
    "\n",
    "### What is this module?\n",
    "\n",
    "The `linked.datasrc.vectors` module provides tools to convert point/vector data into graph data (edge lists) suitable for:\n",
    "- Network analysis\n",
    "- Visualization (force-directed layouts)\n",
    "- Dimensionality reduction\n",
    "- Clustering and community detection\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Scalable**: Designed for 50K-500K points with up to 3000+ dimensions\n",
    "- **Fast**: Approximate methods provide 10-100x speedup\n",
    "- **Flexible**: Multiple algorithms, distance metrics, and parameters\n",
    "- **Research-based**: Implements algorithms from recent papers (UMAP, mutual k-NN)\n",
    "\n",
    "### Installation\n",
    "\n",
    "First, let's install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Uncomment the following lines if you need to install:\n",
    "\n",
    "# !pip install numpy scipy scikit-learn\n",
    "# !pip install pynndescent  # Optional, for 10-100x speedup on large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "# Add the linked package to the path (adjust this to your installation)\n",
    "# sys.path.insert(0, '/path/to/linked')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Quick Start <a id=\"quick-start\"></a>\n",
    "\n",
    "Let's start with the simplest possible example to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Import successful!\n"
     ]
    }
   ],
   "source": [
    "# Import the main functions\n",
    "from linked import knn_graph, mutual_knn_graph, adaptive_knn_graph, epsilon_graph, random_graph\n",
    "\n",
    "print(\"‚úì Import successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your First Graph (1 minute)\n",
    "\n",
    "Let's create some sample data and build a simple k-NN graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 vectors with 20 dimensions\n",
      "\n",
      "Created graph with 500 edges\n",
      "Graph shape: (500, 3)\n",
      "\n",
      "First 5 edges (source, target, weight):\n",
      "[[ 0.         76.          1.22005713]\n",
      " [ 0.         46.          1.24272346]\n",
      " [ 0.         63.          1.27833676]\n",
      " [ 0.         42.          1.34552133]\n",
      " [ 0.         94.          1.39535344]]\n"
     ]
    }
   ],
   "source": [
    "# Create sample data: 100 points in 20 dimensions\n",
    "vectors = np.random.rand(100, 20)\n",
    "print(f\"Created {vectors.shape[0]} vectors with {vectors.shape[1]} dimensions\")\n",
    "\n",
    "# Build a k-NN graph (each point connected to 5 nearest neighbors)\n",
    "graph = knn_graph(vectors, n_neighbors=5)\n",
    "\n",
    "print(f\"\\nCreated graph with {len(graph)} edges\")\n",
    "print(f\"Graph shape: {graph.shape}\")\n",
    "print(f\"\\nFirst 5 edges (source, target, weight):\")\n",
    "print(graph[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "The graph is returned as a numpy array where:\n",
    "- **Column 0**: Source node index\n",
    "- **Column 1**: Target node index  \n",
    "- **Column 2**: Edge weight (distance between nodes)\n",
    "\n",
    "For example, `[0, 15, 1.234]` means:\n",
    "- Node 0 is connected to node 15\n",
    "- The distance between them is 1.234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Graph Construction Methods <a id=\"methods\"></a>\n",
    "\n",
    "The module provides five different methods for constructing graphs from vector data. Let's explore each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 k-Nearest Neighbors (k-NN) Graph\n",
    "\n",
    "The most basic approach: connect each point to its k nearest neighbors.\n",
    "\n",
    "**When to use:**\n",
    "- Standard graph construction\n",
    "- Low to medium dimensional data\n",
    "- When you want a simple, predictable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example 1: Basic k-NN Graph\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 200\n",
    "n_features = 32\n",
    "vectors = np.random.rand(n_samples, n_features)\n",
    "print(f\"Data shape: {vectors.shape}\")\n",
    "\n",
    "# Build k-NN graph\n",
    "graph = knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=10,        # Each point connects to 10 nearest neighbors\n",
    "    metric=\"euclidean\",    # Distance metric\n",
    "    mode=\"distance\",       # Include distance weights\n",
    "    approximate=False      # Use exact nearest neighbors\n",
    ")\n",
    "\n",
    "print(f\"\\nGraph statistics:\")\n",
    "print(f\"  Number of edges: {len(graph)}\")\n",
    "print(f\"  Average edge weight: {np.mean(graph[:, 2]):.4f}\")\n",
    "print(f\"  Min edge weight: {np.min(graph[:, 2]):.4f}\")\n",
    "print(f\"  Max edge weight: {np.max(graph[:, 2]):.4f}\")\n",
    "\n",
    "print(f\"\\nSample edges:\")\n",
    "print(graph[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Distance Metrics\n",
    "\n",
    "Different metrics are appropriate for different types of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different distance metrics\n",
    "vectors = np.random.rand(100, 32)\n",
    "metrics = [\"euclidean\", \"manhattan\", \"cosine\"]\n",
    "\n",
    "print(\"\\nComparing distance metrics:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in metrics:\n",
    "    graph = knn_graph(vectors, n_neighbors=10, metric=metric, approximate=False)\n",
    "    avg_weight = np.mean(graph[:, 2])\n",
    "    print(f\"{metric.capitalize():12s}: {len(graph):4d} edges, avg distance = {avg_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric Selection Guide:**\n",
    "- **Euclidean**: General-purpose, works well for normalized data\n",
    "- **Cosine**: Good for high-dimensional sparse data (e.g., text embeddings)\n",
    "- **Manhattan**: Robust to outliers, good for discrete features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mutual k-NN Graph\n",
    "\n",
    "A more robust variant where an edge exists only if two points are mutual neighbors.\n",
    "\n",
    "**When to use:**\n",
    "- High-dimensional data (reduces \"hub\" effects)\n",
    "- When you want more reliable local structure\n",
    "- Visualization tasks requiring cleaner structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example 2: Mutual k-NN Graph\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vectors = np.random.rand(150, 64)\n",
    "print(f\"Data shape: {vectors.shape}\")\n",
    "\n",
    "# Regular k-NN graph\n",
    "graph_regular = knn_graph(vectors, n_neighbors=10, approximate=False)\n",
    "print(f\"\\nRegular k-NN edges: {len(graph_regular)}\")\n",
    "\n",
    "# Mutual k-NN graph (no connectivity enforcement)\n",
    "graph_mutual = mutual_knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=10,\n",
    "    approximate=False,\n",
    "    ensure_connectivity=\"none\"  # Don't add extra edges for connectivity\n",
    ")\n",
    "print(f\"Mutual k-NN edges: {len(graph_mutual)}\")\n",
    "print(f\"Sparsity reduction: {len(graph_mutual)/len(graph_regular)*100:.1f}%\")\n",
    "\n",
    "# Mutual k-NN with MST connectivity (recommended)\n",
    "graph_mutual_mst = mutual_knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=10,\n",
    "    approximate=False,\n",
    "    ensure_connectivity=\"mst\"  # Add minimum spanning tree edges\n",
    ")\n",
    "print(f\"Mutual k-NN + MST edges: {len(graph_mutual_mst)}\")\n",
    "print(f\"\\nMST adds {len(graph_mutual_mst) - len(graph_mutual)} edges to ensure connectivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Mutual k-NN is Better for High Dimensions:**\n",
    "\n",
    "In high dimensions, some points become \"hubs\" with many incoming connections. Mutual k-NN removes these asymmetric connections, resulting in:\n",
    "- More balanced degree distribution\n",
    "- Better preservation of local structure\n",
    "- Cleaner visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Epsilon-Neighborhood Graph\n",
    "\n",
    "Connect all pairs of points within a fixed radius.\n",
    "\n",
    "**When to use:**\n",
    "- When you have a natural distance threshold\n",
    "- For density-based analysis\n",
    "- When point density varies significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example 3: Epsilon-Neighborhood Graph\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vectors = np.random.rand(100, 16)\n",
    "print(f\"Data shape: {vectors.shape}\")\n",
    "\n",
    "# Try different radii to see effect\n",
    "print(\"\\nTesting different radius values:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for radius in [0.3, 0.5, 0.7, 1.0]:\n",
    "    graph = epsilon_graph(vectors, radius=radius)\n",
    "    avg_degree = len(graph) / len(vectors) if len(graph) > 0 else 0\n",
    "    print(f\"Radius {radius:.1f}: {len(graph):4d} edges, avg degree = {avg_degree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Epsilon graphs can be very sensitive to the radius parameter. Too small and the graph fragments; too large and it becomes dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Adaptive k-NN Graph (UMAP-style)\n",
    "\n",
    "Uses local density estimation to adaptively scale distances, ensuring consistent local connectivity across varying-density regions.\n",
    "\n",
    "**When to use:**\n",
    "- Data with varying density regions\n",
    "- For dimensionality reduction preprocessing\n",
    "- When you want smooth, adaptive weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example 4: Adaptive k-NN Graph (UMAP-style)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create data with varying density: two clusters with different spreads\n",
    "cluster1 = np.random.randn(50, 10) * 0.3 + 0  # Dense cluster\n",
    "cluster2 = np.random.randn(50, 10) * 1.0 + 5  # Sparse cluster\n",
    "vectors = np.vstack([cluster1, cluster2])\n",
    "\n",
    "print(f\"Data shape: {vectors.shape}\")\n",
    "print(\"Two clusters with different densities\\n\")\n",
    "\n",
    "# Standard k-NN\n",
    "graph_standard = knn_graph(vectors, n_neighbors=8, approximate=False)\n",
    "\n",
    "# Adaptive k-NN\n",
    "graph_adaptive = adaptive_knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=8,\n",
    "    local_connectivity=1,  # Min strong connections per point\n",
    "    bandwidth=1.0,         # Gaussian kernel bandwidth\n",
    "    approximate=False\n",
    ")\n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Standard k-NN:  {len(graph_standard)} edges\")\n",
    "print(f\"Adaptive k-NN:  {len(graph_adaptive)} edges\")\n",
    "\n",
    "print(f\"\\nWeight distributions:\")\n",
    "print(f\"Standard - mean: {np.mean(graph_standard[:, 2]):.4f}, std: {np.std(graph_standard[:, 2]):.4f}\")\n",
    "print(f\"Adaptive - mean: {np.mean(graph_adaptive[:, 2]):.4f}, std: {np.std(graph_adaptive[:, 2]):.4f}\")\n",
    "\n",
    "print(\"\\nNote: Adaptive weights are in (0, 1] after exponential transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How Adaptive Weighting Works:**\n",
    "\n",
    "1. Estimates local density around each point\n",
    "2. Scales distances by local density\n",
    "3. Applies Gaussian kernel for smooth weights\n",
    "4. Result: Consistent connectivity regardless of local density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Random Graphs\n",
    "\n",
    "Generate synthetic graphs for testing and benchmarking.\n",
    "\n",
    "**Available models:**\n",
    "- **Erd≈ës-R√©nyi**: Random edges with fixed probability\n",
    "- **Barab√°si-Albert**: Scale-free network with preferential attachment\n",
    "- **Watts-Strogatz**: Small-world network with local clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example 5: Random Graph Generation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_nodes = 50\n",
    "\n",
    "# Erd≈ës-R√©nyi: Each edge exists with probability p\n",
    "graph_er = random_graph(n_nodes, model=\"erdos_renyi\", p=0.1, seed=42)\n",
    "print(f\"Erd≈ës-R√©nyi (p=0.1):         {len(graph_er):3d} edges\")\n",
    "\n",
    "# Barab√°si-Albert: Preferential attachment (m edges per new node)\n",
    "graph_ba = random_graph(n_nodes, model=\"barabasi_albert\", m=2, seed=42)\n",
    "print(f\"Barab√°si-Albert (m=2):       {len(graph_ba):3d} edges\")\n",
    "\n",
    "# Watts-Strogatz: Small-world (k initial degree, p rewiring probability)\n",
    "graph_ws = random_graph(n_nodes, model=\"watts_strogatz\", k=4, p=0.2, seed=42)\n",
    "print(f\"Watts-Strogatz (k=4, p=0.2): {len(graph_ws):3d} edges\")\n",
    "\n",
    "# With random weights\n",
    "graph_weighted = random_graph(\n",
    "    n_nodes,\n",
    "    model=\"erdos_renyi\",\n",
    "    p=0.1,\n",
    "    weighted=True,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"\\nWeighted Erd≈ës-R√©nyi: mean weight = {np.mean(graph_weighted[:, 2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Working Examples <a id=\"examples\"></a>\n",
    "\n",
    "Now let's look at more complete, real-world examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example A: Processing Text Embeddings\n",
    "\n",
    "A common use case is building a graph from text embeddings (e.g., word2vec, BERT, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example A: Text Embeddings\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simulate text embeddings (e.g., from BERT)\n",
    "n_documents = 500\n",
    "embedding_dim = 768  # Typical BERT embedding dimension\n",
    "\n",
    "# Generate random embeddings (in practice, these would come from your model)\n",
    "text_embeddings = np.random.randn(n_documents, embedding_dim)\n",
    "# Normalize for cosine similarity\n",
    "text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "print(f\"Processing {n_documents} documents with {embedding_dim}-dim embeddings\")\n",
    "\n",
    "# Build graph using cosine similarity (appropriate for text)\n",
    "start_time = time.time()\n",
    "graph = knn_graph(\n",
    "    text_embeddings,\n",
    "    n_neighbors=20,\n",
    "    metric=\"cosine\",       # Cosine distance for text\n",
    "    approximate=True,      # Fast approximate search\n",
    "    n_jobs=-1             # Use all CPU cores\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nGraph construction completed in {elapsed:.3f} seconds\")\n",
    "print(f\"Created {len(graph)} edges\")\n",
    "print(f\"Average cosine distance: {np.mean(graph[:, 2]):.4f}\")\n",
    "print(f\"\\nThis graph can be used for:\")\n",
    "print(\"  - Document similarity search\")\n",
    "print(\"  - Topic clustering\")\n",
    "print(\"  - Visualization of document relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example B: Creating Clusters with Different Structures\n",
    "\n",
    "Let's create synthetic data with clear cluster structure and see how different methods handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example B: Clustered Data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create 3 distinct clusters\n",
    "n_per_cluster = 100\n",
    "cluster_centers = np.array([[0, 0], [5, 5], [-5, 5]])\n",
    "\n",
    "clusters = []\n",
    "for center in cluster_centers:\n",
    "    cluster = np.random.randn(n_per_cluster, 2) * 0.5 + center\n",
    "    clusters.append(cluster)\n",
    "\n",
    "vectors = np.vstack(clusters)\n",
    "print(f\"Created {len(vectors)} points in 3 clusters\")\n",
    "\n",
    "# Build mutual k-NN graph with MST connectivity\n",
    "graph = mutual_knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=10,\n",
    "    ensure_connectivity=\"mst\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGraph has {len(graph)} edges\")\n",
    "\n",
    "# Analyze intra-cluster vs inter-cluster edges\n",
    "labels = np.repeat(np.arange(3), n_per_cluster)\n",
    "\n",
    "intra_cluster = 0\n",
    "inter_cluster = 0\n",
    "\n",
    "for source, target, weight in graph:\n",
    "    if labels[int(source)] == labels[int(target)]:\n",
    "        intra_cluster += 1\n",
    "    else:\n",
    "        inter_cluster += 1\n",
    "\n",
    "print(f\"\\nEdge analysis:\")\n",
    "print(f\"  Intra-cluster edges: {intra_cluster} ({intra_cluster/len(graph)*100:.1f}%)\")\n",
    "print(f\"  Inter-cluster edges: {inter_cluster} ({inter_cluster/len(graph)*100:.1f}%)\")\n",
    "print(f\"\\nGood graph construction preserves cluster structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example C: Using Sklearn-Style Estimators\n",
    "\n",
    "The module provides sklearn-compatible estimators for pipeline integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Example C: Sklearn-Style Estimators\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from linked import KNNGraphEstimator, MutualKNNGraphEstimator, AdaptiveKNNGraphEstimator\n",
    "\n",
    "# Sample data\n",
    "vectors = np.random.rand(200, 50)\n",
    "\n",
    "print(\"Creating estimators with different configurations:\\n\")\n",
    "\n",
    "# Standard k-NN estimator\n",
    "est_knn = KNNGraphEstimator(\n",
    "    n_neighbors=15,\n",
    "    metric=\"euclidean\",\n",
    "    approximate=True\n",
    ")\n",
    "graph_knn = est_knn.fit_transform(vectors)\n",
    "print(f\"KNN Estimator:           {len(graph_knn)} edges\")\n",
    "\n",
    "# Mutual k-NN estimator\n",
    "est_mutual = MutualKNNGraphEstimator(\n",
    "    n_neighbors=15,\n",
    "    ensure_connectivity=\"mst\"\n",
    ")\n",
    "graph_mutual = est_mutual.fit_transform(vectors)\n",
    "print(f\"Mutual KNN Estimator:    {len(graph_mutual)} edges\")\n",
    "\n",
    "# Adaptive k-NN estimator\n",
    "est_adaptive = AdaptiveKNNGraphEstimator(\n",
    "    n_neighbors=15,\n",
    "    local_connectivity=1,\n",
    "    bandwidth=1.0\n",
    ")\n",
    "graph_adaptive = est_adaptive.fit_transform(vectors)\n",
    "print(f\"Adaptive KNN Estimator:  {len(graph_adaptive)} edges\")\n",
    "\n",
    "print(\"\\nEstimators can be used in sklearn pipelines!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Performance & Scaling <a id=\"performance\"></a>\n",
    "\n",
    "Let's examine performance characteristics with different dataset sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Comparing Exact vs Approximate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Performance Comparison: Exact vs Approximate\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate larger dataset\n",
    "n_samples = 5000\n",
    "n_features = 256\n",
    "vectors = np.random.rand(n_samples, n_features)\n",
    "\n",
    "print(f\"Testing with {n_samples} samples, {n_features} features\\n\")\n",
    "\n",
    "# Exact k-NN (slower but precise)\n",
    "print(\"Running exact k-NN...\")\n",
    "start = time.time()\n",
    "graph_exact = knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=15,\n",
    "    approximate=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "time_exact = time.time() - start\n",
    "print(f\"  Time: {time_exact:.3f} seconds\")\n",
    "print(f\"  Edges: {len(graph_exact)}\")\n",
    "\n",
    "# Approximate k-NN (faster)\n",
    "print(\"\\nRunning approximate k-NN...\")\n",
    "try:\n",
    "    start = time.time()\n",
    "    graph_approx = knn_graph(\n",
    "        vectors,\n",
    "        n_neighbors=15,\n",
    "        approximate=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    time_approx = time.time() - start\n",
    "    print(f\"  Time: {time_approx:.3f} seconds\")\n",
    "    print(f\"  Edges: {len(graph_approx)}\")\n",
    "    print(f\"\\n  Speedup: {time_exact/time_approx:.1f}x\")\n",
    "except Exception as e:\n",
    "    print(f\"  Approximate method not available (install pynndescent for speedup)\")\n",
    "    print(f\"  Would provide ~10-100x speedup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Scaling Guidelines\n",
    "\n",
    "Here are recommended settings for different dataset sizes:\n",
    "\n",
    "| Dataset Size | Recommended Settings |\n",
    "|--------------|---------------------|\n",
    "| < 1K samples | `approximate=False`, any metric |\n",
    "| 1K - 10K | `approximate=True`, `n_neighbors=15` |\n",
    "| 10K - 100K | `approximate=True`, `n_neighbors=10-15` |\n",
    "| 100K - 500K | `approximate=True`, `n_neighbors=5-10` |\n",
    "| > 500K | Consider batch processing |\n",
    "\n",
    "**Memory Requirements:**\n",
    "\n",
    "For 100K samples √ó 256 features with k=15:\n",
    "- Input vectors: ~200 MB\n",
    "- Output graph: ~36 MB\n",
    "- Intermediate: ~400-600 MB\n",
    "- **Total: ~0.6-1 GB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Optimizing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Parameter Optimization Example\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vectors = np.random.rand(1000, 128)\n",
    "\n",
    "# Test different n_neighbors values\n",
    "print(\"\\nEffect of n_neighbors on graph density:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for k in [5, 10, 15, 20, 30]:\n",
    "    graph = knn_graph(vectors, n_neighbors=k, approximate=False)\n",
    "    avg_degree = len(graph) / len(vectors)\n",
    "    avg_weight = np.mean(graph[:, 2])\n",
    "    print(f\"k={k:2d}: {len(graph):5d} edges, avg_degree={avg_degree:.1f}, avg_weight={avg_weight:.4f}\")\n",
    "\n",
    "print(\"\\nGeneral guidelines:\")\n",
    "print(\"  - Smaller k (5-10): Sparse, emphasize local structure\")\n",
    "print(\"  - Medium k (15-30): Balanced, good for most cases\")\n",
    "print(\"  - Larger k (50+):   Dense, may include noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Best Practices <a id=\"best-practices\"></a>\n",
    "\n",
    "Here are some guidelines for getting the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Data Preprocessing\n",
    "\n",
    "**Always normalize or standardize your data** before graph construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Data Preprocessing Example\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Raw data with different scales\n",
    "raw_data = np.random.rand(200, 10)\n",
    "raw_data[:, 0] *= 100  # First feature has much larger scale\n",
    "\n",
    "print(\"Raw data statistics:\")\n",
    "print(f\"  Feature 0: mean={np.mean(raw_data[:, 0]):.2f}, std={np.std(raw_data[:, 0]):.2f}\")\n",
    "print(f\"  Feature 1: mean={np.mean(raw_data[:, 1]):.2f}, std={np.std(raw_data[:, 1]):.2f}\")\n",
    "\n",
    "# Method 1: Standardization (zero mean, unit variance)\n",
    "standardized_data = (raw_data - np.mean(raw_data, axis=0)) / np.std(raw_data, axis=0)\n",
    "\n",
    "# Method 2: Min-Max normalization (scale to [0, 1])\n",
    "min_vals = np.min(raw_data, axis=0)\n",
    "max_vals = np.max(raw_data, axis=0)\n",
    "normalized_data = (raw_data - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "# Method 3: L2 normalization (for cosine similarity)\n",
    "l2_normalized_data = raw_data / np.linalg.norm(raw_data, axis=1, keepdims=True)\n",
    "\n",
    "# Compare graph construction\n",
    "graph_raw = knn_graph(raw_data, n_neighbors=10, approximate=False)\n",
    "graph_standardized = knn_graph(standardized_data, n_neighbors=10, approximate=False)\n",
    "graph_normalized = knn_graph(normalized_data, n_neighbors=10, approximate=False)\n",
    "\n",
    "print(\"\\nAverage edge weights:\")\n",
    "print(f\"  Raw data:         {np.mean(graph_raw[:, 2]):.4f}\")\n",
    "print(f\"  Standardized:     {np.mean(graph_standardized[:, 2]):.4f}\")\n",
    "print(f\"  Min-Max norm:     {np.mean(graph_normalized[:, 2]):.4f}\")\n",
    "\n",
    "print(\"\\nRecommendation: Standardize or normalize before graph construction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Choosing the Right Method\n",
    "\n",
    "**Decision Tree for Method Selection:**\n",
    "\n",
    "```\n",
    "Start\n",
    "‚îÇ\n",
    "‚îú‚îÄ High-dimensional data (>100 dims)?\n",
    "‚îÇ  ‚îî‚îÄ YES ‚Üí Use mutual_knn_graph with ensure_connectivity=\"mst\"\n",
    "‚îÇ\n",
    "‚îú‚îÄ Varying density regions?\n",
    "‚îÇ  ‚îî‚îÄ YES ‚Üí Use adaptive_knn_graph\n",
    "‚îÇ\n",
    "‚îú‚îÄ Natural distance threshold?\n",
    "‚îÇ  ‚îî‚îÄ YES ‚Üí Use epsilon_graph\n",
    "‚îÇ\n",
    "‚îî‚îÄ Standard case ‚Üí Use knn_graph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Common Pitfalls to Avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Common Pitfalls and Solutions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ùå PITFALL 1: Using k too large\n",
    "   Problem: Graph becomes too dense, includes noise\n",
    "   Solution: Start with k=15, increase only if needed\n",
    "\n",
    "‚ùå PITFALL 2: Not normalizing data\n",
    "   Problem: Features with large scales dominate distance\n",
    "   Solution: Always standardize or normalize first\n",
    "\n",
    "‚ùå PITFALL 3: Using Euclidean for high-D sparse data\n",
    "   Problem: Distance concentration makes neighbors less meaningful\n",
    "   Solution: Use cosine metric for sparse/text data\n",
    "\n",
    "‚ùå PITFALL 4: Forgetting connectivity\n",
    "   Problem: Mutual k-NN can fragment into disconnected components\n",
    "   Solution: Use ensure_connectivity=\"mst\"\n",
    "\n",
    "‚ùå PITFALL 5: Using exact methods on large data\n",
    "   Problem: Very slow for >10K points\n",
    "   Solution: Set approximate=True, install pynndescent\n",
    "\n",
    "‚úÖ BEST PRACTICE: Start simple, iterate based on results\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Integration Examples <a id=\"integration\"></a>\n",
    "\n",
    "Let's see how to integrate the graphs with other tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Converting to NetworkX\n",
    "\n",
    "NetworkX is a popular Python library for network analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Integration: NetworkX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "    \n",
    "    # Create graph\n",
    "    vectors = np.random.rand(50, 10)\n",
    "    edges = knn_graph(vectors, n_neighbors=5)\n",
    "    \n",
    "    # Convert to NetworkX\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights\n",
    "    for source, target, weight in edges:\n",
    "        G.add_edge(int(source), int(target), weight=weight)\n",
    "    \n",
    "    print(f\"Created NetworkX graph with:\")\n",
    "    print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"  Edges: {G.number_of_edges()}\")\n",
    "    print(f\"  Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "    \n",
    "    # Network analysis\n",
    "    print(f\"\\nNetwork metrics:\")\n",
    "    print(f\"  Connected: {nx.is_connected(G)}\")\n",
    "    if nx.is_connected(G):\n",
    "        print(f\"  Diameter: {nx.diameter(G):.2f}\")\n",
    "        print(f\"  Avg path length: {nx.average_shortest_path_length(G):.2f}\")\n",
    "    print(f\"  Clustering coefficient: {nx.average_clustering(G):.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NetworkX not installed. Install with: pip install networkx\")\n",
    "    print(\"\\nExample code:\")\n",
    "    print(\"\"\"\n",
    "    import networkx as nx\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for source, target, weight in edges:\n",
    "        G.add_edge(int(source), int(target), weight=weight)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualization with Force-Directed Layout\n",
    "\n",
    "Create a simple 2D visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Integration: Visualization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create small graph for visualization\n",
    "    vectors = np.random.rand(30, 5)\n",
    "    edges = mutual_knn_graph(vectors, n_neighbors=4, ensure_connectivity=\"mst\")\n",
    "    \n",
    "    # Convert to NetworkX\n",
    "    G = nx.Graph()\n",
    "    for source, target, weight in edges:\n",
    "        G.add_edge(int(source), int(target), weight=weight)\n",
    "    \n",
    "    # Create layout\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color='lightblue',\n",
    "        node_size=500,\n",
    "        alpha=0.9\n",
    "    )\n",
    "    \n",
    "    # Draw edges with varying thickness based on weight\n",
    "    weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    max_weight = max(weights)\n",
    "    edge_widths = [3 * (1 - w/max_weight) for w in weights]  # Thicker = closer\n",
    "    \n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        width=edge_widths,\n",
    "        alpha=0.5,\n",
    "        edge_color='gray'\n",
    "    )\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    \n",
    "    plt.title('Graph Visualization: Mutual k-NN with MST', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Visualization created successfully!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NetworkX or matplotlib not installed\")\n",
    "    print(\"Install with: pip install networkx matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Using Graphs for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Integration: Graph-Based Clustering\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "# Create data with distinct clusters\n",
    "cluster1 = np.random.randn(50, 10) * 0.5 + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "cluster2 = np.random.randn(50, 10) * 0.5 + [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
    "cluster3 = np.random.randn(50, 10) * 0.5 + [-5, -5, -5, -5, -5, -5, -5, -5, -5, -5]\n",
    "vectors = np.vstack([cluster1, cluster2, cluster3])\n",
    "\n",
    "print(f\"Data: {len(vectors)} points in 3 clusters\\n\")\n",
    "\n",
    "# Build graph\n",
    "edges = mutual_knn_graph(vectors, n_neighbors=8, ensure_connectivity=\"none\")\n",
    "\n",
    "# Convert to sparse adjacency matrix\n",
    "n_nodes = len(vectors)\n",
    "row = edges[:, 0].astype(int)\n",
    "col = edges[:, 1].astype(int)\n",
    "data = np.ones(len(edges))\n",
    "adj_matrix = csr_matrix((data, (row, col)), shape=(n_nodes, n_nodes))\n",
    "\n",
    "# Make symmetric\n",
    "adj_matrix = adj_matrix + adj_matrix.T\n",
    "\n",
    "# Find connected components (clusters)\n",
    "n_clusters, labels = connected_components(adj_matrix, directed=False)\n",
    "\n",
    "print(f\"Graph-based clustering results:\")\n",
    "print(f\"  Number of clusters found: {n_clusters}\")\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_size = np.sum(labels == i)\n",
    "    print(f\"  Cluster {i}: {cluster_size} points\")\n",
    "\n",
    "print(\"\\n‚úì Graph structure reveals natural clusters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Key Takeaways\n",
    "\n",
    "### Main Functions\n",
    "\n",
    "| Function | Use Case | Key Parameters |\n",
    "|----------|----------|----------------|\n",
    "| `knn_graph` | General purpose | `n_neighbors=15` |\n",
    "| `mutual_knn_graph` | High dimensions | `ensure_connectivity=\"mst\"` |\n",
    "| `epsilon_graph` | Distance threshold | `radius=0.5` |\n",
    "| `adaptive_knn_graph` | Varying density | `local_connectivity=1` |\n",
    "| `random_graph` | Testing/benchmarking | `model=\"erdos_renyi\"` |\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "from linked import knn_graph, mutual_knn_graph\n",
    "\n",
    "# Basic usage\n",
    "graph = knn_graph(vectors, n_neighbors=15)\n",
    "\n",
    "# For high-dimensional data\n",
    "graph = mutual_knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=15,\n",
    "    ensure_connectivity=\"mst\"\n",
    ")\n",
    "\n",
    "# For large datasets\n",
    "graph = knn_graph(\n",
    "    vectors,\n",
    "    n_neighbors=15,\n",
    "    approximate=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "```\n",
    "\n",
    "### Remember\n",
    "\n",
    "1. **Always preprocess**: Normalize or standardize your data\n",
    "2. **Start simple**: Begin with `knn_graph`, iterate if needed\n",
    "3. **Use approximation**: Set `approximate=True` for datasets >1K points\n",
    "4. **Choose metric wisely**: Cosine for text, Euclidean for general data\n",
    "5. **Ensure connectivity**: Use MST for visualization tasks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Read the [API Reference](linked/misc/API_REFERENCE.md) for complete documentation\n",
    "- Check [examples.py](linked/misc/examples.py) for more advanced usage\n",
    "- Explore the [README](linked/README.md) for detailed explanations\n",
    "\n",
    "---\n",
    "\n",
    "**Happy graphing! üéØ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
